{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data = np.genfromtxt('data/transformed_train.txt',delimiter = None)\n",
    "#train_Y = np.genfromtxt('data/train_Y.txt',delimiter = None)\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "#sc1 = StandardScaler()\n",
    "#X = np.loadtxt(\"data/X_train.txt\",delimiter=None)\n",
    "#Y = np.loadtxt(\"data/Y_train.txt\",delimiter=None)\n",
    "train_data = np.loadtxt(\"data/transformed_train.txt\",delimiter = None)\n",
    "train_Y = np.loadtxt(\"data/train_Y.txt\",delimiter = None)\n",
    "#sc1 = StandardScaler()\n",
    "#sc1.fit(train_data)\n",
    "#train_data = sc1.transform(train_data)\n",
    "#validation_data = np.loadtxt(\"data/reduced_validation.txt\",delimiter = None)\n",
    "#smotetomek = SMOTETomek(random_state = 0)\n",
    "#sc1.fit(train_data)\n",
    "#train_data = sc1.transform(train_data)\n",
    "#train_data,train_Y = smotetomek.fit_sample(train_data,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "alpha = np.zeros(shape=(84,1))\n",
    "weights_models = np.ones(shape=(train_data.shape[0],))/train_data.shape[0]\n",
    "validation_data = np.loadtxt('data/transformed_validation.txt',delimiter = None)\n",
    "validation_Y = np.loadtxt('data/validation_Y.txt',delimiter = None)\n",
    "#predictions_val = np.zeros(shape=(val_data.shape[0],val_data.shape[1]))\n",
    "for i in range(0,84):\n",
    "    model = DecisionTreeClassifier(max_depth = 1)\n",
    "    model.fit(train_data,train_Y,np.atleast_1d(weights_models))\n",
    "    joblib.dump(model,'data/AdaBoost/decision_model_'+str(i)+'.txt')\n",
    "    predictions = model.predict(train_data)\n",
    "    error = np.dot(weights_models,train_Y!=predictions)\n",
    "    alpha[i] = 0.5*np.log((1-error)/error)\n",
    "    weights_models *= np.exp(-alpha[i]*train_Y*predictions)\n",
    "    weights_models /= weights_models.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_predictions = np.zeros(shape=(validation_data.shape[0],))\n",
    "for i in range(0,84):\n",
    "#    for j in range(0,1):\n",
    "    model = joblib.load('data/AdaBoost/decision_model_'+str(i)+'.txt')\n",
    "    validation_predictions += model.predict(validation_data)\n",
    "validation_predictions = np.sign(validation_predictions)\n",
    "#model = LogisticRegression()\n",
    "#model.fit(validation_predictions.reshape(-1,1),validation_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(validation_Y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616972105092\n",
      "[[8439 3893]\n",
      " [5554 6778]]\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(validation_Y,validation_predictions))\n",
    "print(confusion_matrix(validation_Y,validation_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12332\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(validation_Y==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78332\n"
     ]
    }
   ],
   "source": [
    "test_data = np.loadtxt('data/transformed_test.txt',delimiter = None)\n",
    "test_predictions = np.zeros(shape=(test_data.shape[0],))\n",
    "for i in range(0,84):\n",
    "#    for j in range(0,1):\n",
    "    model = joblib.load('data/AdaBoost/decision_model_'+str(i)+'.txt')\n",
    "    test_predictions += model.predict(test_data)\n",
    "test_predictions = np.sign(test_predictions)\n",
    "print(np.count_nonzero(test_predictions==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#max(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640853065196\n",
      "[[8761 3571]\n",
      " [5287 7045]]\n",
      "0.684195588712\n",
      "[[8972 3360]\n",
      " [4429 7903]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "adaboost.fit(train_data,train_Y)\n",
    "gbc.fit(train_data,train_Y)\n",
    "predictions = adaboost.predict(validation_data)\n",
    "gbc_predictions = gbc.predict(validation_data)\n",
    "print(roc_auc_score(validation_Y,predictions))\n",
    "print(confusion_matrix(validation_Y,predictions))\n",
    "print(roc_auc_score(validation_Y,gbc_predictions))\n",
    "print(confusion_matrix(validation_Y,gbc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74273\n"
     ]
    }
   ],
   "source": [
    "predictions = gbc.predict(test_data)\n",
    "print(np.count_nonzero(predictions==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = np.loadtxt('data/reduced_train_svd.txt',delimiter = None)\n",
    "training_Y = np.loadtxt('data/train_Y.txt',delimiter = None)\n",
    "adaboost = AdaBoostClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yte = np.vstack((np.arange(test_data.shape[0]), predictions.T)).T\n",
    "np.savetxt('data/Y_submit.txt', Yte, '%d, %.2f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
